{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6614301f9e4749baa6c9a8332228c0a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1280ca96dfc4ba09bc1eb0acc60e405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b4c45a6f2e4f76a3e6170ac568123b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2871b71e32024a83bc4013299a23a888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dsets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = dsets.MNIST(root='./data', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터를 가방으로 감싸주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.linear(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 3000\n",
    "epochs = 30\n",
    "input_dim = 784\n",
    "output_dim = 10\n",
    "lr_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Loss Fuction 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss() # computes softmax and then the cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimizer 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 모델 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 1.8234401941299438. Accuracy: 68.\n",
      "Iteration: 1000. Loss: 1.570595383644104. Accuracy: 76.\n",
      "Iteration: 1500. Loss: 1.3404805660247803. Accuracy: 80.\n",
      "Iteration: 2000. Loss: 1.3133856058120728. Accuracy: 81.\n",
      "Iteration: 2500. Loss: 0.8355376720428467. Accuracy: 82.\n",
      "Iteration: 3000. Loss: 1.0205930471420288. Accuracy: 83.\n",
      "Iteration: 3500. Loss: 0.7641586661338806. Accuracy: 84.\n",
      "Iteration: 4000. Loss: 0.8875670433044434. Accuracy: 84.\n",
      "Iteration: 4500. Loss: 0.9776996970176697. Accuracy: 84.\n",
      "Iteration: 5000. Loss: 0.7590512037277222. Accuracy: 85.\n",
      "Iteration: 5500. Loss: 0.5568453073501587. Accuracy: 85.\n",
      "Iteration: 6000. Loss: 0.8655368089675903. Accuracy: 85.\n",
      "Iteration: 6500. Loss: 0.5001879334449768. Accuracy: 85.\n",
      "Iteration: 7000. Loss: 0.6552404165267944. Accuracy: 86.\n",
      "Iteration: 7500. Loss: 0.7174976468086243. Accuracy: 86.\n",
      "Iteration: 8000. Loss: 0.9715489149093628. Accuracy: 86.\n",
      "Iteration: 8500. Loss: 0.5835276246070862. Accuracy: 86.\n",
      "Iteration: 9000. Loss: 0.4376707375049591. Accuracy: 86.\n",
      "Iteration: 9500. Loss: 0.4840327203273773. Accuracy: 86.\n",
      "Iteration: 10000. Loss: 0.5160177946090698. Accuracy: 87.\n",
      "Iteration: 10500. Loss: 0.7116718292236328. Accuracy: 87.\n",
      "Iteration: 11000. Loss: 0.5461861491203308. Accuracy: 87.\n",
      "Iteration: 11500. Loss: 0.9254468083381653. Accuracy: 87.\n",
      "Iteration: 12000. Loss: 0.5096419453620911. Accuracy: 87.\n",
      "Iteration: 12500. Loss: 0.3464932441711426. Accuracy: 87.\n",
      "Iteration: 13000. Loss: 0.6391273736953735. Accuracy: 87.\n",
      "Iteration: 13500. Loss: 0.32090091705322266. Accuracy: 87.\n",
      "Iteration: 14000. Loss: 0.6815288066864014. Accuracy: 87.\n",
      "Iteration: 14500. Loss: 0.5354639291763306. Accuracy: 87.\n",
      "Iteration: 15000. Loss: 0.3646768629550934. Accuracy: 87.\n",
      "Iteration: 15500. Loss: 0.3540445566177368. Accuracy: 88.\n",
      "Iteration: 16000. Loss: 0.4930207133293152. Accuracy: 87.\n",
      "Iteration: 16500. Loss: 0.40295740962028503. Accuracy: 88.\n",
      "Iteration: 17000. Loss: 0.6705163717269897. Accuracy: 88.\n",
      "Iteration: 17500. Loss: 0.44431328773498535. Accuracy: 88.\n",
      "Iteration: 18000. Loss: 0.44060081243515015. Accuracy: 88.\n",
      "Iteration: 18500. Loss: 0.29261314868927. Accuracy: 88.\n",
      "Iteration: 19000. Loss: 0.7414798736572266. Accuracy: 88.\n",
      "Iteration: 19500. Loss: 0.4002726674079895. Accuracy: 88.\n",
      "Iteration: 20000. Loss: 0.4889691174030304. Accuracy: 88.\n",
      "Iteration: 20500. Loss: 0.3450711965560913. Accuracy: 88.\n",
      "Iteration: 21000. Loss: 0.3514334261417389. Accuracy: 88.\n",
      "Iteration: 21500. Loss: 0.6292517781257629. Accuracy: 88.\n",
      "Iteration: 22000. Loss: 0.6664980053901672. Accuracy: 88.\n",
      "Iteration: 22500. Loss: 0.43328857421875. Accuracy: 88.\n",
      "Iteration: 23000. Loss: 0.4020904302597046. Accuracy: 88.\n",
      "Iteration: 23500. Loss: 0.7401005625724792. Accuracy: 88.\n",
      "Iteration: 24000. Loss: 0.30750572681427. Accuracy: 88.\n",
      "Iteration: 24500. Loss: 0.47413331270217896. Accuracy: 88.\n",
      "Iteration: 25000. Loss: 0.6321874856948853. Accuracy: 88.\n",
      "Iteration: 25500. Loss: 0.1075037494301796. Accuracy: 88.\n",
      "Iteration: 26000. Loss: 0.7137760519981384. Accuracy: 88.\n",
      "Iteration: 26500. Loss: 0.5566592216491699. Accuracy: 89.\n",
      "Iteration: 27000. Loss: 0.26789069175720215. Accuracy: 89.\n",
      "Iteration: 27500. Loss: 0.5186441540718079. Accuracy: 88.\n",
      "Iteration: 28000. Loss: 0.45199665427207947. Accuracy: 89.\n",
      "Iteration: 28500. Loss: 0.39303058385849. Accuracy: 89.\n",
      "Iteration: 29000. Loss: 0.3676656186580658. Accuracy: 89.\n",
      "Iteration: 29500. Loss: 0.7606413960456848. Accuracy: 89.\n",
      "Iteration: 30000. Loss: 0.579889178276062. Accuracy: 89.\n",
      "Iteration: 30500. Loss: 0.6407089233398438. Accuracy: 89.\n",
      "Iteration: 31000. Loss: 0.7162255644798279. Accuracy: 89.\n",
      "Iteration: 31500. Loss: 0.31236690282821655. Accuracy: 89.\n",
      "Iteration: 32000. Loss: 0.26637229323387146. Accuracy: 89.\n",
      "Iteration: 32500. Loss: 0.4546155631542206. Accuracy: 89.\n",
      "Iteration: 33000. Loss: 0.4783840477466583. Accuracy: 89.\n",
      "Iteration: 33500. Loss: 0.41322436928749084. Accuracy: 89.\n",
      "Iteration: 34000. Loss: 0.5941528081893921. Accuracy: 89.\n",
      "Iteration: 34500. Loss: 0.56153804063797. Accuracy: 89.\n",
      "Iteration: 35000. Loss: 0.3024083077907562. Accuracy: 89.\n",
      "Iteration: 35500. Loss: 1.0837562084197998. Accuracy: 89.\n",
      "Iteration: 36000. Loss: 0.3062632083892822. Accuracy: 89.\n",
      "Iteration: 36500. Loss: 0.2259131222963333. Accuracy: 89.\n",
      "Iteration: 37000. Loss: 0.1896994560956955. Accuracy: 89.\n",
      "Iteration: 37500. Loss: 0.22727851569652557. Accuracy: 89.\n",
      "Iteration: 38000. Loss: 0.25727710127830505. Accuracy: 89.\n",
      "Iteration: 38500. Loss: 0.38022544980049133. Accuracy: 89.\n",
      "Iteration: 39000. Loss: 0.46606314182281494. Accuracy: 89.\n",
      "Iteration: 39500. Loss: 0.9439538717269897. Accuracy: 89.\n",
      "Iteration: 40000. Loss: 0.2161296010017395. Accuracy: 89.\n",
      "Iteration: 40500. Loss: 0.40232014656066895. Accuracy: 89.\n",
      "Iteration: 41000. Loss: 0.4551987946033478. Accuracy: 89.\n",
      "Iteration: 41500. Loss: 0.28894737362861633. Accuracy: 89.\n",
      "Iteration: 42000. Loss: 0.17861072719097137. Accuracy: 89.\n",
      "Iteration: 42500. Loss: 0.541136622428894. Accuracy: 89.\n",
      "Iteration: 43000. Loss: 0.23587258160114288. Accuracy: 89.\n",
      "Iteration: 43500. Loss: 0.2975677251815796. Accuracy: 89.\n",
      "Iteration: 44000. Loss: 0.3629205822944641. Accuracy: 89.\n",
      "Iteration: 44500. Loss: 0.6357350945472717. Accuracy: 89.\n",
      "Iteration: 45000. Loss: 0.5362548828125. Accuracy: 90.\n",
      "Iteration: 45500. Loss: 0.6968836784362793. Accuracy: 90.\n",
      "Iteration: 46000. Loss: 0.2741764485836029. Accuracy: 90.\n",
      "Iteration: 46500. Loss: 0.9342083930969238. Accuracy: 90.\n",
      "Iteration: 47000. Loss: 0.334499716758728. Accuracy: 90.\n",
      "Iteration: 47500. Loss: 0.5085256099700928. Accuracy: 90.\n",
      "Iteration: 48000. Loss: 0.4920603334903717. Accuracy: 90.\n",
      "Iteration: 48500. Loss: 0.4903515875339508. Accuracy: 90.\n",
      "Iteration: 49000. Loss: 0.317635715007782. Accuracy: 90.\n",
      "Iteration: 49500. Loss: 0.34785518050193787. Accuracy: 90.\n",
      "Iteration: 50000. Loss: 0.17799372971057892. Accuracy: 90.\n",
      "Iteration: 50500. Loss: 0.6801565885543823. Accuracy: 90.\n",
      "Iteration: 51000. Loss: 0.2591690719127655. Accuracy: 90.\n",
      "Iteration: 51500. Loss: 0.3360203206539154. Accuracy: 90.\n",
      "Iteration: 52000. Loss: 0.39567482471466064. Accuracy: 90.\n",
      "Iteration: 52500. Loss: 0.20261265337467194. Accuracy: 90.\n",
      "Iteration: 53000. Loss: 0.38195618987083435. Accuracy: 90.\n",
      "Iteration: 53500. Loss: 0.1316230744123459. Accuracy: 90.\n",
      "Iteration: 54000. Loss: 0.687716007232666. Accuracy: 90.\n",
      "Iteration: 54500. Loss: 0.2882938086986542. Accuracy: 90.\n",
      "Iteration: 55000. Loss: 0.27419060468673706. Accuracy: 90.\n",
      "Iteration: 55500. Loss: 0.34056419134140015. Accuracy: 90.\n",
      "Iteration: 56000. Loss: 0.128046452999115. Accuracy: 90.\n",
      "Iteration: 56500. Loss: 0.30811527371406555. Accuracy: 90.\n",
      "Iteration: 57000. Loss: 0.4212459921836853. Accuracy: 90.\n",
      "Iteration: 57500. Loss: 0.44787389039993286. Accuracy: 90.\n",
      "Iteration: 58000. Loss: 0.4664217233657837. Accuracy: 90.\n",
      "Iteration: 58500. Loss: 0.1582513004541397. Accuracy: 90.\n",
      "Iteration: 59000. Loss: 0.6065258979797363. Accuracy: 90.\n",
      "Iteration: 59500. Loss: 0.5089265704154968. Accuracy: 90.\n",
      "Iteration: 60000. Loss: 0.15047287940979004. Accuracy: 90.\n",
      "Iteration: 60500. Loss: 0.23094870150089264. Accuracy: 90.\n",
      "Iteration: 61000. Loss: 0.5547318458557129. Accuracy: 90.\n",
      "Iteration: 61500. Loss: 0.43084490299224854. Accuracy: 90.\n",
      "Iteration: 62000. Loss: 0.6809220910072327. Accuracy: 90.\n",
      "Iteration: 62500. Loss: 0.23870182037353516. Accuracy: 90.\n",
      "Iteration: 63000. Loss: 0.627242922782898. Accuracy: 90.\n",
      "Iteration: 63500. Loss: 0.056743767112493515. Accuracy: 90.\n",
      "Iteration: 64000. Loss: 0.28834933042526245. Accuracy: 90.\n",
      "Iteration: 64500. Loss: 0.24241843819618225. Accuracy: 90.\n",
      "Iteration: 65000. Loss: 0.3260533809661865. Accuracy: 90.\n",
      "Iteration: 65500. Loss: 0.5508107542991638. Accuracy: 90.\n",
      "Iteration: 66000. Loss: 0.23320886492729187. Accuracy: 90.\n",
      "Iteration: 66500. Loss: 0.7466322183609009. Accuracy: 90.\n",
      "Iteration: 67000. Loss: 0.5225242376327515. Accuracy: 90.\n",
      "Iteration: 67500. Loss: 0.3239384889602661. Accuracy: 90.\n",
      "Iteration: 68000. Loss: 0.29007184505462646. Accuracy: 90.\n",
      "Iteration: 68500. Loss: 0.3753511309623718. Accuracy: 90.\n",
      "Iteration: 69000. Loss: 0.5175409913063049. Accuracy: 90.\n",
      "Iteration: 69500. Loss: 0.30576691031455994. Accuracy: 90.\n",
      "Iteration: 70000. Loss: 0.15587355196475983. Accuracy: 90.\n",
      "Iteration: 70500. Loss: 0.21870304644107819. Accuracy: 90.\n",
      "Iteration: 71000. Loss: 0.4299062192440033. Accuracy: 90.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 71500. Loss: 0.440302312374115. Accuracy: 90.\n",
      "Iteration: 72000. Loss: 0.4418069124221802. Accuracy: 90.\n",
      "Iteration: 72500. Loss: 0.22131511569023132. Accuracy: 90.\n",
      "Iteration: 73000. Loss: 0.7139031887054443. Accuracy: 90.\n",
      "Iteration: 73500. Loss: 0.495399534702301. Accuracy: 90.\n",
      "Iteration: 74000. Loss: 0.23940664529800415. Accuracy: 90.\n",
      "Iteration: 74500. Loss: 0.2361273169517517. Accuracy: 90.\n",
      "Iteration: 75000. Loss: 0.426893413066864. Accuracy: 90.\n",
      "Iteration: 75500. Loss: 0.449937105178833. Accuracy: 90.\n",
      "Iteration: 76000. Loss: 0.35485008358955383. Accuracy: 90.\n",
      "Iteration: 76500. Loss: 0.3736417889595032. Accuracy: 90.\n",
      "Iteration: 77000. Loss: 0.40784233808517456. Accuracy: 90.\n",
      "Iteration: 77500. Loss: 0.34199756383895874. Accuracy: 90.\n",
      "Iteration: 78000. Loss: 0.8015603423118591. Accuracy: 90.\n",
      "Iteration: 78500. Loss: 0.37549981474876404. Accuracy: 90.\n",
      "Iteration: 79000. Loss: 0.3466058373451233. Accuracy: 90.\n",
      "Iteration: 79500. Loss: 0.23188024759292603. Accuracy: 90.\n",
      "Iteration: 80000. Loss: 0.2012147158384323. Accuracy: 90.\n",
      "Iteration: 80500. Loss: 0.10489857196807861. Accuracy: 90.\n",
      "Iteration: 81000. Loss: 0.6016375422477722. Accuracy: 90.\n",
      "Iteration: 81500. Loss: 0.06775467097759247. Accuracy: 90.\n",
      "Iteration: 82000. Loss: 0.44069337844848633. Accuracy: 90.\n",
      "Iteration: 82500. Loss: 0.35967931151390076. Accuracy: 90.\n",
      "Iteration: 83000. Loss: 0.25070884823799133. Accuracy: 90.\n",
      "Iteration: 83500. Loss: 0.14311856031417847. Accuracy: 90.\n",
      "Iteration: 84000. Loss: 0.33601653575897217. Accuracy: 90.\n",
      "Iteration: 84500. Loss: 0.3093051016330719. Accuracy: 90.\n",
      "Iteration: 85000. Loss: 0.5312765836715698. Accuracy: 90.\n",
      "Iteration: 85500. Loss: 0.685107946395874. Accuracy: 90.\n",
      "Iteration: 86000. Loss: 0.3186366856098175. Accuracy: 90.\n",
      "Iteration: 86500. Loss: 0.14426672458648682. Accuracy: 90.\n",
      "Iteration: 87000. Loss: 0.13621793687343597. Accuracy: 90.\n",
      "Iteration: 87500. Loss: 0.14093822240829468. Accuracy: 90.\n",
      "Iteration: 88000. Loss: 0.30789715051651. Accuracy: 90.\n",
      "Iteration: 88500. Loss: 0.31092506647109985. Accuracy: 90.\n",
      "Iteration: 89000. Loss: 0.25872519612312317. Accuracy: 90.\n",
      "Iteration: 89500. Loss: 0.47388148307800293. Accuracy: 90.\n",
      "Iteration: 90000. Loss: 0.20648445188999176. Accuracy: 90.\n",
      "Iteration: 90500. Loss: 0.42940282821655273. Accuracy: 90.\n",
      "Iteration: 91000. Loss: 0.32431888580322266. Accuracy: 90.\n",
      "Iteration: 91500. Loss: 0.36680254340171814. Accuracy: 90.\n",
      "Iteration: 92000. Loss: 0.381238728761673. Accuracy: 90.\n",
      "Iteration: 92500. Loss: 0.3651069104671478. Accuracy: 90.\n",
      "Iteration: 93000. Loss: 0.0819801613688469. Accuracy: 90.\n",
      "Iteration: 93500. Loss: 0.10186886787414551. Accuracy: 90.\n",
      "Iteration: 94000. Loss: 0.17429861426353455. Accuracy: 90.\n",
      "Iteration: 94500. Loss: 0.3803650140762329. Accuracy: 90.\n",
      "Iteration: 95000. Loss: 0.12536922097206116. Accuracy: 90.\n",
      "Iteration: 95500. Loss: 0.20046298205852509. Accuracy: 90.\n",
      "Iteration: 96000. Loss: 0.4770732820034027. Accuracy: 90.\n",
      "Iteration: 96500. Loss: 0.6746992468833923. Accuracy: 90.\n",
      "Iteration: 97000. Loss: 0.09139136224985123. Accuracy: 90.\n",
      "Iteration: 97500. Loss: 0.23101013898849487. Accuracy: 90.\n",
      "Iteration: 98000. Loss: 0.1523851901292801. Accuracy: 90.\n",
      "Iteration: 98500. Loss: 0.16863471269607544. Accuracy: 90.\n",
      "Iteration: 99000. Loss: 0.4440213441848755. Accuracy: 90.\n",
      "Iteration: 99500. Loss: 0.15094268321990967. Accuracy: 90.\n",
      "Iteration: 100000. Loss: 0.1869044005870819. Accuracy: 90.\n",
      "Iteration: 100500. Loss: 0.1416129320859909. Accuracy: 90.\n",
      "Iteration: 101000. Loss: 0.30281347036361694. Accuracy: 91.\n",
      "Iteration: 101500. Loss: 0.1438187211751938. Accuracy: 90.\n",
      "Iteration: 102000. Loss: 0.2308024913072586. Accuracy: 91.\n",
      "Iteration: 102500. Loss: 0.3720053434371948. Accuracy: 91.\n",
      "Iteration: 103000. Loss: 0.26618650555610657. Accuracy: 90.\n",
      "Iteration: 103500. Loss: 0.1940889060497284. Accuracy: 91.\n",
      "Iteration: 104000. Loss: 0.36943644285202026. Accuracy: 91.\n",
      "Iteration: 104500. Loss: 0.13744108378887177. Accuracy: 91.\n",
      "Iteration: 105000. Loss: 0.8089843988418579. Accuracy: 91.\n",
      "Iteration: 105500. Loss: 0.2712324261665344. Accuracy: 91.\n",
      "Iteration: 106000. Loss: 0.2901886999607086. Accuracy: 90.\n",
      "Iteration: 106500. Loss: 0.09576376527547836. Accuracy: 91.\n",
      "Iteration: 107000. Loss: 0.47410184144973755. Accuracy: 91.\n",
      "Iteration: 107500. Loss: 0.5118610262870789. Accuracy: 91.\n",
      "Iteration: 108000. Loss: 0.24357537925243378. Accuracy: 91.\n",
      "Iteration: 108500. Loss: 0.19555459916591644. Accuracy: 91.\n",
      "Iteration: 109000. Loss: 0.4734067916870117. Accuracy: 91.\n",
      "Iteration: 109500. Loss: 0.24807514250278473. Accuracy: 91.\n",
      "Iteration: 110000. Loss: 0.6265116930007935. Accuracy: 91.\n",
      "Iteration: 110500. Loss: 0.22243563830852509. Accuracy: 91.\n",
      "Iteration: 111000. Loss: 0.7654678225517273. Accuracy: 91.\n",
      "Iteration: 111500. Loss: 0.45185139775276184. Accuracy: 91.\n",
      "Iteration: 112000. Loss: 0.20830915868282318. Accuracy: 91.\n",
      "Iteration: 112500. Loss: 0.24483716487884521. Accuracy: 91.\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(int(epochs)):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1, 28 * 28))\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        iter+=1\n",
    "        if iter%500==0:\n",
    "            # calculate Accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in test_loader:\n",
    "                images = Variable(images.view(-1, 28*28))\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total+= labels.size(0)\n",
    "                # for gpu, bring the predicted and labels back to cpu fro python operations to work\n",
    "                correct+= (predicted == labels).sum()\n",
    "            accuracy = 100 * correct/total\n",
    "            print(\"Iteration: {}. Loss: {}. Accuracy: {}.\".format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고사이트 : https://towardsdatascience.com/logistic-regression-on-mnist-with-pytorch-b048327f8d19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
